{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "import subprocess\n",
    "import os\n",
    "import fileinput\n",
    "import math\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/NHF/images/2018/'\n",
    "i = 0\n",
    "labels = []\n",
    "img_list = []\n",
    "# Find all .midi files in the given directory and convert them first into CSV files, after that the CSVs into .png files\n",
    "for filename in glob.glob(path + '*.png'):\n",
    "    #print(filename)\n",
    "    img = cv2.imread(filename,  cv2.IMREAD_UNCHANGED)\n",
    "    #print(img)\n",
    "    #Append current picture to the list of  all pictures\n",
    "    img_list.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20dd8031c50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview image \n",
    "PREVIEW_ROWS = 4\n",
    "PREVIEW_COLS = 7\n",
    "PREVIEW_MARGIN = 16\n",
    "SAVE_FREQ = 100\n",
    "\n",
    "EPOCHS = 20000\n",
    "BATCH_SIZE = 128\n",
    "DATA_PATH = 'c:/NHF/classical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_generator(seed_size, channels):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(128 * 11 * 25, input_dim=seed_size))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((11, 25, 128)))\n",
    "    model.add(Conv2DTranspose(64, kernel_size=(2,2), strides=(2,2)))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2DTranspose(32, kernel_size=(2,2), strides=(2,2)))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2DTranspose(channels, kernel_size=(2,2), strides=(2,2)))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    noise = Input(shape=(seed_size,))\n",
    "    img = model(noise)\n",
    "\n",
    "    return Model(noise, img)\n",
    "'''\n",
    "def build_generator(seed_size, channels):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(11*25*128,activation=\"relu\",input_dim=seed_size))\n",
    "    model.add(Reshape((11,25,128)))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(64,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "   \n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(64,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    # Final CNN layer\n",
    "    model.add(Conv2D(channels,kernel_size=3,padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    input = Input(shape=(seed_size,))\n",
    "    generated_image = model(input)\n",
    "\n",
    "    return Model(input,generated_image)\n",
    "'''\n",
    "def build_discriminator(image_shape):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=(88,200,4), padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    img = Input(shape=image_shape)\n",
    "    validity = model(img)\n",
    "\n",
    "    return Model(img, validity)\n",
    "\n",
    "'''\n",
    "def build_discriminator(image_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=image_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    input_image = Input(shape=image_shape)\n",
    "\n",
    "    validity = model(input_image)\n",
    "\n",
    "    return Model(input_image, validity)\n",
    "'''\n",
    "def save_images(cnt,noise):\n",
    "    image_array = np.full(( \n",
    "      PREVIEW_MARGIN + (PREVIEW_ROWS * (88+PREVIEW_MARGIN)), \n",
    "      PREVIEW_MARGIN + (PREVIEW_COLS * (200+PREVIEW_MARGIN)), 4), \n",
    "      255, dtype=np.uint8)\n",
    "  \n",
    "    generated_images = generator.predict(noise)\n",
    "\n",
    "    generated_images = 0.5 * generated_images + 0.5\n",
    "\n",
    "    image_count = 0\n",
    "    for row in range(PREVIEW_ROWS):\n",
    "        for col in range(PREVIEW_COLS):\n",
    "            r = row * (88+16) + PREVIEW_MARGIN\n",
    "            c = col * (200+16) + PREVIEW_MARGIN\n",
    "            image_array[r:r+88,c:c+200] = generated_images[image_count] * 255\n",
    "            image_count += 1\n",
    "\n",
    "          \n",
    "    output_path = os.path.join(DATA_PATH,'output')\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "  \n",
    "    filename = os.path.join(output_path,f\"train-{cnt}.png\")\n",
    "    im = Image.fromarray(image_array)\n",
    "    im.save(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kajud\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 44, 100, 32)       1184      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 44, 100, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 44, 100, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 50, 64)        18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 23, 51, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 23, 51, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 23, 51, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 23, 51, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 26, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 12, 26, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 12, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 26, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 26, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 12, 26, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 12, 26, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 79872)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 79873     \n",
      "=================================================================\n",
      "Total params: 470,369\n",
      "Trainable params: 469,473\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\kajud\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 35200)             3555200   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 35200)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 11, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 22, 50, 64)        32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 22, 50, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 22, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 44, 100, 32)       8224      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 44, 100, 32)       128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 44, 100, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 88, 200, 4)        516       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 88, 200, 4)        0         \n",
      "=================================================================\n",
      "Total params: 3,597,156\n",
      "Trainable params: 3,596,964\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "SEED_SIZE = 100\n",
    "IMAGE_CHANNELS = 4\n",
    "image_shape = (88,200,4)\n",
    "optimizer = Adam(1.5e-4,0.5) # learning rate and momentum adjusted from paper\n",
    "\n",
    "discriminator = build_discriminator(image_shape)\n",
    "discriminator.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "generator = build_generator(SEED_SIZE,IMAGE_CHANNELS)\n",
    "\n",
    "random_input = Input(shape=(SEED_SIZE,))\n",
    "\n",
    "generated_image = generator(random_input)\n",
    "\n",
    "discriminator.trainable = False\n",
    "\n",
    "validity = discriminator(generated_image)\n",
    "\n",
    "combined = Model(random_input,validity)\n",
    "combined.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kajud\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 0, Discriminator accuarcy: 0.23046875, Generator accuracy: 0.921875\n",
      "Epoch 100, Discriminator accuarcy: 1.0, Generator accuracy: 0.0\n",
      "Epoch 200, Discriminator accuarcy: 1.0, Generator accuracy: 0.0\n",
      "Epoch 300, Discriminator accuarcy: 1.0, Generator accuracy: 0.0\n",
      "Epoch 400, Discriminator accuarcy: 1.0, Generator accuracy: 0.0\n",
      "Epoch 500, Discriminator accuarcy: 1.0, Generator accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "keras.initializers.Initializer()\n",
    "\n",
    "y_real = np.ones((BATCH_SIZE,1))\n",
    "y_fake = np.zeros((BATCH_SIZE,1))\n",
    "\n",
    "fixed_seed = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, SEED_SIZE))\n",
    "\n",
    "cnt = 1\n",
    "for epoch in range(EPOCHS):\n",
    "    idx = np.random.randint(0,x_train.shape[0],BATCH_SIZE)\n",
    "    x_real = x_train[idx]\n",
    "\n",
    "    # Generate some images\n",
    "    seed = np.random.normal(0,1,(BATCH_SIZE,SEED_SIZE))\n",
    "    x_fake = generator.predict(seed)\n",
    "    \n",
    "    discriminator.trainable = True\n",
    "    generator.trainable = False\n",
    "    \n",
    "    # Train discriminator on real and fake\n",
    "    discriminator_metric_real = discriminator.train_on_batch(x_real,y_real)\n",
    "    discriminator_metric_generated = discriminator.train_on_batch(x_fake,y_fake)\n",
    "    discriminator_metric = 0.5 * np.add(discriminator_metric_real,discriminator_metric_generated)\n",
    "    \n",
    "    discriminator.trainable = False\n",
    "    generator.trainable = True\n",
    "    \n",
    "    # Train generator on Calculate losses\n",
    "    generator_metric = combined.train_on_batch(seed,y_real)\n",
    "    \n",
    "    # Time for an update?\n",
    "    if epoch % SAVE_FREQ == 0:\n",
    "        save_images(cnt, fixed_seed)\n",
    "        cnt += 1\n",
    "        print(f\"Epoch {epoch}, Discriminator accuarcy: {discriminator_metric[1]}, Generator accuracy: {generator_metric[1]}\")\n",
    "        \n",
    "generator.save(os.path.join(DATA_PATH,\"music.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
